# まとめ資料
資料作成時期:2026/01

**`結果まとめ` ：研究関連の全データ**
**`[レンダリング]`**：刺激画像をレンダリングするためのコード、objファイル等をまとめたフォルダ
**`[解析01]`**：NMDS空間の構築&プロクラステス変換後のパーミュテーションテストにより、知覚空間の類似度を定量化するための解析用のコードをまとめたフォルダ
**`[解析02]`**：平均輝度とRMSコントラストを使用して、類似度判断データをロジスティック回帰をするための解析用のコードをまとめたフォルダ
**`[実験生データ]`**：本実験で収集した実験データと使用した実験用コード。日本人、オーストラリア人それぞれ。
**`[予備実験]`**：レンダリングした144枚の刺激画像から64枚の刺激画像を選択するための予備実験データと予備実験用のコード

下記の順に追っていくと、これまでの解析をトレースする形になります。

### レンダリング：144枚の刺激画像作成
`scenes`：objファイルと環境照明用のファイル
`レンダリング結果`：blob(64枚)、dragon(64枚)、bunny(64枚)のレンダリング結果
`レンダリング結果(背景灰色_トリミング済み)`：レンダリング結果を実験用に灰色背景に変更し、画像サイズをすべて同じにしたバージョンです。
※この灰色の輝度値の決め方は、背景の変更を永井先生にやっていただいたので詳細は覚えていないのですが、確か全刺激の刺激部分の平均輝度だった気がします。トリミングのほうも先生にやっていただきました。
`レンダリング用コード`：blob、dragon、bunnyそれぞれのレンダリング用コード

### 予備実験：本実験で使用する刺激の選択
`experiment_code`：予備実験で使用したコード
`実験結果`：予備実験結果(3名)：144枚の刺激画像に対して、14個の各形容詞が当てはまっているか否かのバイナリ形式で144*14の行列として結果が保存されている。
`予備実験で使用した刺激(144枚)`
`本実験で使用した刺激(64枚)`
`stimulus_list_pre.mat`：実験データは、各144枚の刺激画像にナンバリングを行い、保存しています。そのナンバリングの対応付け表です。

`クラスタリング解析`:　144枚から64枚の刺激を選択するためにおこなったクラスタリング解析

- `cluster_analysis.m`
   ３名の予備実験結果に対し、クラスタリング解析を行うコード

- `divide_image_to_cluster.m`
   クラスタリングの結果ごとに画像をフォルダに保存するコード
- `cluster_results`
  - クラスタごとに画像をフォルダにまとめている。そのフォルダのなかにあるフォルダ(例：`Cluster1`の中の`Cluster1`)にはそのクラスタから本実験用に選択された画像が保存されている。刺激選択の方法として、各Clusterから最低１枚は選択されるように選択した。

  - `stimuli`：本実験用に選択された画像64枚

### 実験生データ：実験用コードと実験結果
`オーストラリア`
`日本`
どちらのフォルダも
`exp1_results`：実験１(類似度判断実験)の結果
`exp2_results`：実験２(形容詞評価実験)の結果
`exp3_results`：実験３(半透明感評価実験)の結果
`experiment_codes`：実験用コード
`stimulus_list_main.mat`：実験データは、各64枚の刺激画像にナンバリングを行って、保存しています。そのナンバリングの対応付け表です。
で構成

- exp1_results
実験１は、１セッション200試行で、1試行から6つの類似度判断データが得られるため、200×6=1200行で構成。各行は [23 12 14 12 1]というような形で保存。この例でいうと、23と14が比較画像、12が参照画像のナンバリングを表しています。[23 12 14 12 1]が意味することは、23の比較画像が14の比較画像より、12の参照画像に素材の類似度がより似ているとなります。最後の「1」は、23の方が14より12に似ているということを意味します。

※ややこしいですが、正直最初の3つの数字(例でいうと 23 12 14)をみるだけで十分です。最初の23がより参照画像に似ている比較画像、2番目が参照画像、3番目が14がもう一方の比較画像を意味するため、残りの4番目と5番目の数字は気にしなくても大丈夫です。

- exp2_results
実験2は、64枚の刺激画像×14個の形容詞評価なので、各被験者ごとに64×14の行列に保存されています。行は、ナンバリングに対応しています。

- exp3_results
実験3は、5回繰り返し×64枚の刺激画像なので、各被験者ごとに5×64の行列に保存されています。列はナンバリングに対応しています。
※実験３の結果はあまり信用できないと想います。オーストラリア人のなかで3~4人ほどの被験者はTranslucencyの定義または、大小の付け方がわからずスマホで検索していたため、バイアスはかなり含まれているかもしれません。

### 解析01：
`NMDS空間`：NMDSの知覚空間を構築するためのコード

- nmds_analysis_set：NMDSを実行するための、Generalized Non-metric Multidimensional Scaling Toolbox一式。このフォルダ内にある`SeDuMi` という外部の最適化ライブラリがNMDS実行に必須なので、matlabでpathにまず追加してください(install_sedumiでインストールを完了させる必要がある場合もあり)。

- nmds_ws2：NMDS用のコード
　-  `使用データ` : `output_data_exp1_au.txt`がオーストラリア人の、`output_data_exp1_jp.txt`が日本人の全類似度判断データを結合したものになっている。10人の被験者×1セッション1200個の類似度判断データ×3セッションで=36000行の類似度判断データで構成されている。

- `nmds_analysis_ver2.m`：NMDSにおける最適な正則化項を決定し、その正則化項における、NMDS空間を構築するコード
　- クロスバリデーションにより、正則化項を変化させながらNMDSを実行し、検証誤差が最小になるように、λを決定。
　- `結果`のファイルには、`X`：64次元のNMDSの座標データ、`best_lambda`：最適な正則化バラメータ、`train_errs, val_errs, test_errs`：交差検証での各λにおける学習誤差、検証誤差、テスト誤差 のリスト、`lambda_values`：テストした λの全候補リストがオーストラリア(eng)、日本(jp)それぞれで保存されている。
　※コードでミスをしていたため、5次元で累積寄与率が両方95%を超えると以前行っていましたが、実際はオーストラリアが94.40%と少し足りませんでした
- 累積寄与率計算用
  15次元までのNMDS空間に対して、累積寄与率を計算するコード

`プロクラステス解析`：構築した知覚空間から空間の類似度を評価するためのコード

1. パーミュテーションテスト用の知覚空間を1000個作成
    - `for_permutation`：オーストラリア人＋日本人　被験者合計20名の類似度判断データ　
    -  `permutation_make_txt_files.py` ：`for_permutation`のフォルダからランダムに10名のデータを選び、それを結合して36000×5のパーミュテーションテスト用類似度判断データ、残りの10名でもう一つの36000×5のパーミュテーションテスト用類似度判断データを作成。それらをパーミュテーションテスト用に1000個作成。

2. `example.m`： それらのパーミュテーションテスト用データを用いてNMDSにより、知覚空間を構築。(構築した1000個の知覚空間の座標データ)×2は、1次元目から5次元目までを`permutation_result_remaining_2`と`permutation_result_selected_2`にそれぞれ保存した。
※exapmle.mで使用した正則化項は、**常に**`nmds_analysis_ver2.m`でオーストラリアのときに最適だとされたλを使用した。

3. パーミュテーションテスト： 
   - `NMDS_5次元データ`というフォルダにある`example2.m`を実行することで、**実際**のオーストラリア人10名と日本人10名それぞれで、NMDS空間を構築できる。５次元までの座標が`オーストラリア`と`日本`のフォルダに保存されている。
   - `procrustes_disparity.py`：実際の知覚空間の類似度判断指標(disparity)を計算できる。ここで、使用する次元(1-5次元or 2-5次元)を変更したり、どの刺激を使用するか(全体or 光沢あり群or 光沢なし群)を変更して、disparityを計算できる。
   - `permutation_test.py`：パーミュテーション用の知覚空間データと`procrustes_disparity.py`で計算したdisparityを用いて、パーミュテーションテストを行うことができる。このコードでは、`procrustes_disparity.py`で設定した次元数と使用する刺激数を合わせることに注意。
  
`補足`：視覚学会で少し言及した、群内での知覚空間の共通性を評価するためのleave-one-out交差検証のコード `nmds_leave_one_out.m`が入っています。`exp1_results_combine_au`と`exp1_results_combine_jp`は被験者ごとに、実験1の3セッションの結果を結合したものを、オーストラリアと日本それぞれで保存したものです。
### 解析02：
`mask`：画像特徴量を算出するために、各画像の物体部分を真っ黒にした画像。背景をそのまま、物体部分を真っ黒にしただけ。
`刺激(光沢有無ごと)`：解析02では、刺激を光沢の有無で分けたため、その２つ群を分けて保存してある。画像名にあるナンバリングは、`実験生データ`の`stimulus_list_main.mat`と同じになっている。

`帰無分布のデータ`：パーミュテーションテストを行うためのデータ作成用コード
- `帰無分布作成用`：

1. `bootstrap_sampling_72000.m`：解析01のnmds_ws2にある全オーストラリア人の類似度データを結合した`output_data_exp1_au.txt` (36000×5)と、全日本人の類似度判断データを結合した`output_data_exp1_jp.txt`(36000×5)を結合した`output_data_exp1_mix.txt` (72000×5)を使用し、720000列の中から36000列を復元抽出するを1000回行うためのコード。1000個のデータは`bootstrapped_files_mix_42_resampled` に保存。
2. `extract_matrix.m`：その復元抽出されたデータから、光沢あり/なし刺激群のみの類似度判断のみを抽出するコード。光沢あり刺激群の判断のみが抽出されたものが保存されているフォルダは、`output_for_svm_1_resampled`、光沢なし刺激群の判断のみが抽出されたものが保存されているフォルダは、`output_for_svm_2_resampled`　になっている。
3. `data_split_1000_fix_seed.py`は、`output_for_svm_1_resampled`と`output_for_svm_2_resampled`を訓練データとテストデータに分割するコード。その分割されたデータたちは、`使用データ(訓練とテスト)`に保存されている。`svm_permutation_1_resampled`が光沢ありの刺激群用、`svm_permutation_2_resampled`が光沢なしの刺激群用になっている。

- `ロジスティック回帰のコード`：`permutation_lr_cluster1_fix.py`が光沢あり用の、`permutation_lr_cluster2_fix.py`が光沢なし用のロジスティック回帰のコードになっている。
- `data`：解析02フォルダ内にある`data`フォルダは、オーストラリアの実験データを結合した`output_data_exp1_au.txt` (36000×5)から、光沢ありの類似度データを抜き出した`extracted_data_aut_1.mat`と、光沢なしのデータを抜き出した`extracted_data_aut_2.mat`、日本の実験データを結合した`output_data_exp1_jp.txt` (36000×5)から、光沢ありの類似度データを抜き出した`extracted_data_jp_1.mat`と、光沢なしのデータを抜き出した`extracted_data_jp_2.mat`となっている。データ抽出に使用したコードは`extract_need_matrix.m`。
- `results`：解析02フォルダにあるresultsにロジスティック回帰の結果を保存している。

**補足：キャリブレーション関連について書いておきます。**
1. ディスプレイには オーストラリアではColor Edge CG319X、日本では、ColorEdge CG2730を使用しました。オーストラリアでのキャリブレーションはColor Edge CG319Xのセルフキャリブレーションを行いました。セルフキャリブレーションはCAL2の設定である  Brightness：120cd/m^2、Black Level ：min、White Point：6500K、Gamma(EOTF)：2.20、Gamma Policy：Standard、Color Gamut：sRGB、Gamut Clipping：off をtarget settingとしました。日本の方でも、EX4 Calibration Sensorを使用して、オーストラリアのtarget setting と同じになるようにsettingをしてキャリブレーションを行いました。
2. visual angleは、bunnyが縦10.547°×横9.235°、blobが縦9.673°×横10.547°、dragonが縦9.673°×横14.466°
3. 被験者とディスプレイの距離は、ディスプレイの大きさがオーストラリアと日本で異なっていたため、オーストラリアで85cm、日本で65cmに設定しました。
4. 被験者は、日本人は全員男性(金子研と一部渡辺研)、オーストラリア人は、７名男性、3名女性です。年齢は、確認し忘れていたので、日本人の方は確認しておきます。
